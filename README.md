# What is this?
An MNIST classifier!

The final architecture ended up being:
- 284 input layers
- 200 hidden layers
- 10 output layers

The net was trained over 7 epochs with a learning rate of 0.297635 (optimal lr holding the epoch and hidden layer counts constant).
